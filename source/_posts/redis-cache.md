---
title: redis-面试-持久化、淘汰策略等
date: 2023-03-20 19:10:36
tags:
- Redis
- 面试
categories:
- Redis
---
## 内存淘汰策略
Redis 中提供了 8 种内存淘汰策略：
* volatile-lru：针对设置了过期时间的 key，使用 LRU 算法进行淘汰
* allkeys-lru：针对所有 key 使用 LRU 算法进行淘汰
* volatile-lfu：针对设置了过期时间的 key，使用 LFU 算法进行淘汰
* allkeys-lfu：针对所有 key 使用 LFU 算法进行淘汰
* volatile-random: 从设置了过期时间的 key 中随机删除
* allkeys-random: 从所有 key 中随机删除
* volatile-ttl：删除最近过期的 key
* noeviction（默认策略）：不删除 key，返回 OOM 错误，只能读取不能写入

Redis中采用的LRU算法是**近似LRU算法**，首先LRU是证选择最久未访问的 key 进行淘汰，近似 LRU 算法是对少量 key 进行采样（默认为 5 个），将采样 key 放入一个淘汰池中，淘汰池默认最多存储 16 个 key，每轮淘汰循环淘汰采样 key 中访问时间最早的 key，直到释放足够的内存空间。Redis不使用真正的 LRU 实现的原因是真正的 LRU 实现需要更多的内存。（终究还是内存太贵啊~）

Redis中采用的LFU算法是**近似LFU算法**,在 LFU 模式下，Redis 会尝试跟踪记录 key 的访问频率，因此将很少使用的 key 淘汰。这意味着经常使用的 key 更有可能保留在内存中。**LFU 近似算法**：它使用 “Morris 计数器” 近似计数算法来估计对象访问频率，核心思想就是令访问频率+1 是有概率的，且访问频率越高时要 +1 概率越小。

为什么 Redis 需要**淘汰池**？
淘汰池，用于存储采样到的样本。对于lru,lfu,ttl类型的淘汰策略，会为采样出来的 key 计算一个评估用的值，取名为 idle。lru 的 idle 是当前和最后一次访问的时间间隔，lfu 的 idle 需要根据当前和最后一次访问的时间间隔和对象的访问频度来做计算，而 ttl 的 idle 就是距离过期时间还有多少毫秒，总的来说， idle 越小则表示 key 越热。当淘汰池满了，会淘汰 idle 最小的数据，也就是将下标为 0 的样本从淘汰池中移除掉，其余样本向前移动一个位置。淘汰池按 idle 升序排列，每次采样结束后，从淘汰池末尾开始向前遍历，找到idle 最大的 key 并将它删除。
具体是什么作用呢？**1. 提升淘汰的精准度：** 当进行过几轮淘汰后，淘汰池将会被装满，每次淘汰能进行比较的样本数就变多了。那么样本数越多，当然淘汰越精准。**2. 提升性能**： 淘汰池是一种空间换时间的操作。假如没有淘汰池，那么需要提高每轮采样数才能取得很好的淘汰精准度，而每轮采样数调整得越多，性能也就越差。而淘汰池的存在能让每轮少量采样到后面也能得到很好的淘汰精准度，并不需要提高每轮采样数，从而也就节省了每轮淘汰开销，从另一个角度来说就是提升了性能。

## 过期Key的删除策略
定时删除：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。
惰性删除；不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。
定期删除；每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。

为什么删除了很多 key 内存占用还是很高？
* 如果使用了 unlink 进行删除，那么很可能是因为大部分 key 的内存还未来得及被异步回收。
* 如果使用了 del 进行删除，内存占用仍然还是很高，那么可能配置项 `lazyfree_lazy_user_del` 不为 0，此时 del 也会使用懒惰删除的方式，那么原因就可能和上面说的一样了。

## 缓存穿透，缓存击穿，缓存雪崩问题
1. **_缓存穿透_**
什么是缓存穿透： 用户查询不存在的数据。
缓存穿透会有什么问题： 如果出现大量查询不存在数据的请求，轻则增加数据库压力，重则将数据库打 垮。
解决方案：
* 校验参数： 适用于能够界定一个合法查询范围的场景，直接屏蔽范围外的非法参数。
* 缓存空值： 这是一种通用的做法，把查询结果为空值的参数也缓存下来，下次查询时就可以直接从缓存取出空值返回。
* 布隆过滤器
**_缓存击穿_**
什么是缓存击穿： 用户查询缓存已失效的数据。
缓存击穿会有什么问题： 如果出现大量查询缓存已失效的数据，轻则增加数据库压力，重则将数据库打垮。
解决方案：
* 分布式锁： 当查询发现缓存不存在时，在缓存中设置关于该 key 的分布式锁，从数据库查询到结果并更新缓存后解锁。在第一个查询解锁之前，其余查询相同 key 的线程只能阻塞等待解锁，此时解锁后可以直接从缓存获取数据。
* 热点缓存不过期： 如果能发现什么数据是热点的话，可以不设置过期时间。比如做社交平台的话，我们可以让百万粉丝以上大 v 的用户信息等缓存不会过期。
* 续期： 缓存被访问时我们就为它进行续期，也可以访问次数到一个阈值后再进行续期，从而让热点缓存不要失效。（但是冷门数据过期后，突然有大量查询的场景这个方案是防不住的）
**_缓存雪崩_**
什么是缓存雪崩： 大量热点数据同时失效。
缓存雪崩会有什么问题： 如果出现大量热点数据同时失效，随后这些热点数据还在被大量查询，轻则增加数据库压力，重则将数据库打垮。
解决方案：
* 分布式锁： 讲过啦！
* 热点缓存不过期： 讲过啦！
* 续期： 讲过啦！
* 过期时间加随机数： 更新缓存并设置过期时间的时候，不要固定过期时间，选用一个固定值 + 随机值，让缓存不要在同一时间过期。

## 持久化
1. RDB(Redis Database)是 Redis 的持久化机制之一，中文一般叫它内存快照。
**RDB 存储形式**： RDB 是以二进制形式存储数据的。
**RDB 生成时机**： RDB 可以执行 SAVE（同步保存） 或者 BGSAVE（创建子进程后台保存）命令主动开始 RDB 的持久化过程。除此之外，RDB 还有被动持久化策略，被动持久化是由服务器定时任务（ServerCron）检查并执行的，该策略可以自己在 redis.conf 配置文件中进行配置，默认被动持久化时机如下：
* 900 秒内发生 1 次修改，距离上次保存超过 900 秒后则创建子进程进行 RDB 持久化。
* 300 秒内发生 10 次修改，距离上次保存超过 300 秒后则创建子进程进行 RDB 持久化。
* 60 秒内发生 10000 次修改，距离上次保存超过 60 秒后则创建子进程进行 RDB 持久化。
**RDB 如何存储**： RDB 存储时首先创建一个临时文件，先写入 REDIS + RDB 版本号，再写入一些关于服务器当前状态和 RDB 文件的辅助信息，之后遍历所有数据库（Redis 有 16 个库）里的键值对，为每个键值对选择合适的编码，能压缩存储的就压缩，将它们以二进制形式写入 RDB 临时文件。
**RDB 生成时写入数据怎么办**： 这个问题实际上是操作系统解决的，操作系统用的是写时复制（Copy-On-Write） 机制，父子进程共享的内存是只读的，如果哪一个进程要写入，则会将发生写入的页拷贝一份（谁写谁拷贝），修改自己的页表内容，之后在拷贝的页上修改数据。RDB 生成在 COW 机制下，父进程最多会复制一倍的内存。
**RDB 的优点：**
* RDB 以二进制形式存储数据，并且尽量选择压缩数据存储，所以 RDB 文件一个优点是节省空间。
* RDB 是数据库在某个时刻的内存快照，恢复速度快。
**RDB 的缺点：**
* 由于 COW 机制的存在，如果在后台生成 RDB 时写入数据较多会比较消耗性能和内存空间。
* RDB 被动持久化策略会有丢失部分新数据的风险。 虽然可以自己配置策略，但一般也不会令 RDB 持久化得太频繁，生成越频繁性能越差。
2. AOF（Append-Only-Files） 是可以看作是一种增量日志文件，日志的内容是以 RESP 协议格式（Redis 设计的网络传输格式）保存的写命令。默认不开启 AOF 持久化，需要修改配置文件开启。
**_AOF 写入时机_**： 每次执行完写操作的命令都会将该命令以 RESP 协议格式写入 AOF 缓冲区。
always：(每次执行完都写入)Redis 在每轮事件循环的前置处理函数中，将 AOF 缓冲区中的所有内容通过 write 系统调用函数追加写入 AOF 文件（此时在内核缓冲区），随后立即调用 fsync 系统调用函数将内核缓冲区的内容刷盘。该策略可靠性最好，但是性能最低。
everysec：(每秒写入)Redis 在每轮事件循环的前置处理函数中，将 AOF 缓冲区中的内容通过 write 系统调用函数追加写入 AOF 文件（此时在内核缓冲区），如果距离上次刷盘超过 1s ，就向 AOF FSYNC 类型的后台线程提交一个刷盘任务。everysec 是默认 AOF 刷盘策略，该策略在性能和可靠性都是适中的。
no： (不主动写入)Redis 在每轮事件循环的前置处理函数中，将 AOF 缓冲区中的内容通过 write 系统调用函数追加写入 AOF 文件（此时在内核缓冲区），不主动调用 fsync，让刷盘时机由操作系统控制。性能最好，可靠性最低。
**_AOF 重写_**： 创建一个子进程，创建一个临时文件，遍历每个数据库，分析每个键值对的内容和状态，用对应的设置命令写入临时文件。临时文件写完后，用配置的 AOF 文件名将其重命名，最后关闭子进程。
**AOF 需要重写的原因：** AOF 文件记录了很多写命令，其中可能有很多是针对同个 key 的写命令，但是一般来说只有最后一次修改有效，所以我们记录了很多无效命令，这会导致占用很多的内存空间。所以 AOF重写的好处就是能够节省 AOF 文件的占用空间，同时剔除了无效命令还能使恢复速度加快。
**AOF 重写时机：**
* 使用 BGREWRITEAOF 命令主动执行后台重写。
* AOF 文件占用空间到达上次重写的 2 倍，被动执行后台重写。
注：AOF 重写时如果父进程有数据写入，那么也是通过写时复制机制来保证数据安全的。还有，AOF 只有后台进程重写，没有在主进程重写的。
_AOF 的优点_：
AOF 数据完整性较 RDB 更好。
_AOF 的缺点：_
AOF 文件记录写命令，并不使用二进制形式和压缩存储，占用空间较大。
AOF 机制下通过执行记录的命令来进行数据恢复，恢复速度较慢。

3. 混合持久化：混合持久化是 Redis 4.0 推出的功能，它是在 AOF 文件里前面存储 RDB 格式数据，后面存储 AOF 格式数据。 数据恢复的时候先根据 RDB 部分快速恢复，再根据 AOF 部分靠执行命令恢复数据。
4. MP-AOF（Multi Part-AOF）是 Redis 7 推出的 AOF 机制。它将 AOF 分成了四类文件：
基本文件（Base）： Base 文件是执行 AOF 重写生成的文件，有 RDB 和 AOF 两种格式，默认是生成RDB 文件，清单文件中只会有一个 Base 文件。Base 文件名格式为： {配置 AOF 文件名}.{序列号}.base.rdb 或 {配置 AOF 文件名}.{序列号}.base.aof 。（感觉基本文件叫起来很怪，所以直接叫Base）
增量文件（Incr）： Incr 文件是最近一次 AOF 重写后记录的所有写命令。清单文件中可能会有多个Incr 文件，Incr 文件在 AOF 重写时创建，但如果 AOF 重写中途中止了，重试重写的时候又会创建一个 Incr文件来记录新的写命令。Incr 文件名格式为： {配置 AOF 文件名}.{序列号}.incr.aof 。（我们提到增量文件也不用中文名，而是说 Incr）
历史文件（History）： 当 AOF 重写成功之后，之前的 base 和 incr 文件将成为历史文件。 历史文件会通过后台线程异步删除。
清单文件（Manifest）： 清单文件用于跟踪和管理其余类型的文件，记录格式为： `file {文件名} seq {序列号} type {文件类型首字母} `。
**MP-AOF 解决什么问题：**
* 减少 AOF 重写期间记录写命令带来的内存开销： 之前的 AOF 机制如果在 AOF 重写期间收到写命令，是将这些命令存储在内存中，待重写完成后再把这些命令追加写入 AOF 文件。那么，如果重写期间收到大量写命令的话，存储这些命令将是一笔不小的内存开销。而 MP-AOF 在 AOF 重写期间是创建了一个新的Incr 文件，用来记录重写期间以及之后收到的写命令，于是就减少了内存开销。
* 减少 AOF 重写时的硬盘 IO 次数： 之前的 AOF 机制为了尽量减少重写完成后，重写期间的写命令占用内存太多，所以会让执行 AOF 重写的子进程把一些重写期间的写命令写入文件，子进程完成重写任务后调用 fsync 刷盘并关闭文件，AOF 重写完成后再将剩余的命令写入重写后的文件，最后再调用一次 fsync 保证落盘。所以和 MP-AOF 在重写期间专门创建一个 Incr 文件来写入命令相比，旧机制硬盘 IO 次数更多了。
* AOF 重写完成后不造成主进程阻塞： 之前的 AOF 机制由于将重写期间的写命令存到内存，那么重写完成后需要把内存中剩余的命令追加写入 AOF 文件并调用 fsync 刷盘，如果需要写的命令很多则可能会导致主进程阻塞。而 MP-AOF 在重写期间创建一个新的 Incr 文件来记录之后的写命令，和平时的 AOF 文件一样边写边刷盘（和配置的持久化策略有关），不会重写完成时突然要将大量命令写入文件中。

**AOF 开启了 always 策略能保证命令一定都落盘吗？**
很遗憾，并不能。首先，写 AOF 缓冲区，AOF 写文件 + 刷盘和执行命令这三样就不在同一个函数里,写 AOF 缓冲区是执行完命令之后，AOF 写文件 + 刷盘时机是每一轮事件循环的前置处理函数，虽然执行完命令到刷盘这个时间间隔很短很短，但是从理论上讲这个时候宕机还是会丢数据的。如果说已经调用 write写入内核缓冲区了，操作系统没挂后面还能让操作系统自动 fsync 刷盘，但是调用 write 之前已经挂了就没救了。同时不止是考虑这个时间间隔，fsync 之后就把事情交给硬件了，有没有成功落盘也要考虑硬件因素。